{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes neuronales 5\n",
    "\n",
    "Vamos a crear una red neuronal para tratar ahora con un conjunto mucho más grande, el *dataset* MNIST. Verás que, a medida que tratamos con conjuntos mayores, el tiempo de procesamiento se incrementa y la necesidad de contar con una GPU crece al mismo ritmo. \n",
    "\n",
    "\n",
    "### Conjunto MNIST\n",
    "\n",
    "El [conjunto MNIST](https://en.wikipedia.org/wiki/MNIST_database) está formado por 70.000 imágenes de dígitos manuscritos del 0 al 9 con un tamaño de 28x28 en escala de grises. A su vez, el conjunto se divide en 60.000 imágenes para entrenamiento y 10.000 para test.\n",
    "\n",
    "<img src=\"imgs/mnist.jpg\" width=\"80%\">\n",
    "\n",
    "Vamos a utilizar este *dataset* para entrenar una red y ver qué precisión obtenemos al clasificar el conjunto de test. Piensa bien lo que pretendemos lograr: **hacer una red que será capaz de “ver”**, aunque, por ahora, solo sean imágenes de dos dimensiones.\n",
    "\n",
    "\n",
    "El conjunto MNIST es muy popular y se utiliza mucho para aprender y probar redes, así que Keras ya lo incluye como parte de la librería."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importar Keras y mnist data\n",
    "\n",
    "import keras\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train), (x_test, ytest) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,  52, 241,  86,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         13,  13, 108, 137, 137, 137, 238, 254,  24,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 121,\n",
       "        254, 254, 254, 254, 254, 254, 254, 254, 103,   2,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  23, 149, 222,\n",
       "        254, 248, 229, 237, 254, 246, 184, 105, 241,  18,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 115, 254, 248,\n",
       "        134,  75,   0,  91, 254,  91,   0,   0,  90,   7,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  83, 254, 143,\n",
       "          0,   0,  63, 235, 224,  37,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  38, 254, 238,\n",
       "         71,  11, 204, 205,  17,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  31, 238, 254,\n",
       "        237, 194, 254, 155,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  71, 237,\n",
       "        254, 254, 178,  16,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 174,\n",
       "        254, 254, 203,  41,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  34, 235,\n",
       "        254, 254, 254, 149,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  12, 167, 254,\n",
       "        201, 198, 254, 238,  75,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  78, 254, 214,\n",
       "         15,  12, 205, 254, 239,  35,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  27, 239, 254, 162,\n",
       "          0,   0, 193, 254, 254,  43,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 138, 254, 238,  51,\n",
       "          0,   0, 193, 254, 225,  27,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  10, 194, 254, 101,   0,\n",
       "          0,   0, 193, 254, 125,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  25, 254, 220,   9,   0,\n",
       "          0, 109, 249, 186,   5,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 141, 254, 217,  20, 113,\n",
       "        201, 250, 254, 125,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 250, 254, 253, 245, 254,\n",
       "        254, 254, 131,   3,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   1,  91, 255, 255, 255, 255,\n",
       "        166,  39,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[125]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# veamos la imagen\n",
    "\n",
    "image = np.array(x_train[120], dtype='float')\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = np.array(x_test[10], dtype='float')\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También es necesario saber en qué rango de valores se mueven nuestras muestras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#max, min values\n",
    "max(x_train[125].reshape(784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(x_train[125].reshape(784))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que cada pixel es un byte con un rango de valores que va desde el 0 hasta el 255 en formato entero. Esta escala no es muy adecuada para la red. Podemos facilitar mucho el trabajo de entrenamiento si transformamos esta escala en otra centrada en el 0 y con un rango de valores entre -0.5 y 0.5. Y, por supuesto, en formato real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# particionar la data en test y train\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train /= 255  # normaliza los datos 0-1\n",
    "x_test /= 255  # normaliza los datos 0-1\n",
    "\n",
    "x_train -= 0.5 # desplazamos el rango a -0.5 y 0.5\n",
    "x_test -= 0.5 # desplazamos el rango a -0.5 y 0.5\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# escalar los rangos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#max, min values\n",
    "max(x_train[125].reshape(784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#max, min values\n",
    "min(x_train[125].reshape(784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
       "       [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
       "       [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
       "       ...,\n",
       "       [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
       "       [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
       "       [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
       "       [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
       "       [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
       "       ...,\n",
       "       [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
       "       [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
       "       [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora preparamos las etiquetas transformándolas a formato *one_hot*. Keras tiene funciones para ello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train,10)\n",
    "ytest  = keras.utils.to_categorical(ytest,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot encoding\n",
    "y_train[125]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest[125]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparación del modelo\n",
    "\n",
    "Tenemos que clasificar imágenes en diez categorías distintas, luego la capa final tendrá diez salidas. En cuanto a la capa de entrada, tenemos una matriz de $28 \\times 28$. Lo que vamos a hacer es transformarla en un vector de $784$ componentes (\n",
    "$28\\times28=784$). Simplemente tomaremos cada fila de la matriz y las iremos colocando secuencialmente.\n",
    "\n",
    "Para la capa o capas ocultas vamos a probar primero con una capa oculta con 20 neuronas. Recuerda que estos son los **hiperparámetros** de los que ya hemos hablado. No hay forma de saber *a priori* cuál es el número óptimo de capas ni de neuronas por capa oculta.\n",
    "\n",
    "Como funciones de activación utilizaremos sigmoides y, en la capa final, softmax.\n",
    "\n",
    "En lugar de definir la red de nuevo con el modelo secuencial de Keras, vamos a hacerlo con la [API funcional](https://keras.io/getting-started/functional-api-guide/). Esta API nos sirve para poder definir modelos más complejos que los simplemente creados a partir de acumular capas apiladas. Hay redes que tienen arquitecturas donde hay capas compartidas, las salidas de una capa pueden ir a capas separadas varias capas, etc. Hay una gran variedad. \n",
    "\n",
    "Por supuesto, la red que vamos a hacer ahora la podríamos hacer perfectamente con el modelo secuencial (y hasta nos sería más fácil), pero vamos a aprender a utilizar esta API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurar la red\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(input_dim = 784, units=20, activation='sigmoid'))\n",
    "model.add(Dense(units=10,activation='softmax'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse',optimizer=keras.optimizers.SGD(lr=1), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si te has fijado, la API funcional usa la función <code>Dense(units=20, activation='sigmoid')(inputs)</code> para crear una capa en lugar del método <code>model.add(Dense(units=20, activation='sigmoid', input_dim=784))</code> del modelo. Esto nos da libertad para asignar la salida de una capa a la entrada de la capa que queramos, no obligatoriamente a la siguiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durante el entrenamiento vamos a ir viendo también cómo va evolucionando el *accuracy* del conjunto de test. Cuando usamos el conjunto de test de esta manera se suele llamar **conjunto de validación**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3750/3750 [==============================] - 4s 920us/step - loss: 0.0531 - accuracy: 0.6292\n",
      "Epoch 2/100\n",
      "3750/3750 [==============================] - 3s 907us/step - loss: 0.0153 - accuracy: 0.9051\n",
      "Epoch 3/100\n",
      "3750/3750 [==============================] - 3s 891us/step - loss: 0.0128 - accuracy: 0.9192\n",
      "Epoch 4/100\n",
      "3750/3750 [==============================] - 3s 918us/step - loss: 0.0112 - accuracy: 0.9288\n",
      "Epoch 5/100\n",
      "3750/3750 [==============================] - 3s 908us/step - loss: 0.0102 - accuracy: 0.9359\n",
      "Epoch 6/100\n",
      "3750/3750 [==============================] - 3s 925us/step - loss: 0.0095 - accuracy: 0.9404\n",
      "Epoch 7/100\n",
      "3750/3750 [==============================] - 3s 907us/step - loss: 0.0095 - accuracy: 0.9398\n",
      "Epoch 8/100\n",
      "3750/3750 [==============================] - 3s 914us/step - loss: 0.0086 - accuracy: 0.9450\n",
      "Epoch 9/100\n",
      "3750/3750 [==============================] - 3s 920us/step - loss: 0.0082 - accuracy: 0.9488\n",
      "Epoch 10/100\n",
      "3750/3750 [==============================] - 4s 941us/step - loss: 0.0077 - accuracy: 0.9517\n",
      "Epoch 11/100\n",
      "3750/3750 [==============================] - 3s 918us/step - loss: 0.0077 - accuracy: 0.9521\n",
      "Epoch 12/100\n",
      "3750/3750 [==============================] - 3s 912us/step - loss: 0.0075 - accuracy: 0.9540\n",
      "Epoch 13/100\n",
      "3750/3750 [==============================] - 3s 927us/step - loss: 0.0074 - accuracy: 0.9540\n",
      "Epoch 14/100\n",
      "3750/3750 [==============================] - 3s 910us/step - loss: 0.0072 - accuracy: 0.9557\n",
      "Epoch 15/100\n",
      "3750/3750 [==============================] - 4s 938us/step - loss: 0.0067 - accuracy: 0.9593\n",
      "Epoch 16/100\n",
      "3750/3750 [==============================] - 3s 895us/step - loss: 0.0067 - accuracy: 0.9583\n",
      "Epoch 17/100\n",
      "3750/3750 [==============================] - 3s 912us/step - loss: 0.0065 - accuracy: 0.9608\n",
      "Epoch 18/100\n",
      "3750/3750 [==============================] - 3s 909us/step - loss: 0.0064 - accuracy: 0.9603\n",
      "Epoch 19/100\n",
      "3750/3750 [==============================] - 3s 914us/step - loss: 0.0063 - accuracy: 0.9618\n",
      "Epoch 20/100\n",
      "3750/3750 [==============================] - 3s 897us/step - loss: 0.0061 - accuracy: 0.9630\n",
      "Epoch 21/100\n",
      "3750/3750 [==============================] - 3s 917us/step - loss: 0.0060 - accuracy: 0.9646\n",
      "Epoch 22/100\n",
      "3750/3750 [==============================] - 3s 932us/step - loss: 0.0060 - accuracy: 0.9640\n",
      "Epoch 23/100\n",
      "3750/3750 [==============================] - 3s 922us/step - loss: 0.0057 - accuracy: 0.9660\n",
      "Epoch 24/100\n",
      "3750/3750 [==============================] - 3s 915us/step - loss: 0.0057 - accuracy: 0.9652\n",
      "Epoch 25/100\n",
      "3750/3750 [==============================] - 3s 925us/step - loss: 0.0057 - accuracy: 0.9654\n",
      "Epoch 26/100\n",
      "3750/3750 [==============================] - 3s 925us/step - loss: 0.0057 - accuracy: 0.9659\n",
      "Epoch 27/100\n",
      "3750/3750 [==============================] - 3s 919us/step - loss: 0.0055 - accuracy: 0.9663\n",
      "Epoch 28/100\n",
      "3750/3750 [==============================] - 3s 918us/step - loss: 0.0054 - accuracy: 0.9676\n",
      "Epoch 29/100\n",
      "3750/3750 [==============================] - 3s 913us/step - loss: 0.0052 - accuracy: 0.9686\n",
      "Epoch 30/100\n",
      "3750/3750 [==============================] - 3s 910us/step - loss: 0.0053 - accuracy: 0.9690\n",
      "Epoch 31/100\n",
      "3750/3750 [==============================] - 3s 916us/step - loss: 0.0052 - accuracy: 0.9690\n",
      "Epoch 32/100\n",
      "3750/3750 [==============================] - 3s 901us/step - loss: 0.0050 - accuracy: 0.9700\n",
      "Epoch 33/100\n",
      "3750/3750 [==============================] - 3s 913us/step - loss: 0.0051 - accuracy: 0.9697\n",
      "Epoch 34/100\n",
      "3750/3750 [==============================] - 3s 900us/step - loss: 0.0051 - accuracy: 0.9687\n",
      "Epoch 35/100\n",
      "3750/3750 [==============================] - 3s 898us/step - loss: 0.0049 - accuracy: 0.9703\n",
      "Epoch 36/100\n",
      "3750/3750 [==============================] - 3s 911us/step - loss: 0.0049 - accuracy: 0.9711\n",
      "Epoch 37/100\n",
      "3750/3750 [==============================] - 3s 903us/step - loss: 0.0046 - accuracy: 0.9737\n",
      "Epoch 38/100\n",
      "3750/3750 [==============================] - 3s 896us/step - loss: 0.0047 - accuracy: 0.9725\n",
      "Epoch 39/100\n",
      "3750/3750 [==============================] - 3s 913us/step - loss: 0.0046 - accuracy: 0.9736\n",
      "Epoch 40/100\n",
      "3750/3750 [==============================] - 3s 891us/step - loss: 0.0047 - accuracy: 0.9724\n",
      "Epoch 41/100\n",
      "3750/3750 [==============================] - 3s 904us/step - loss: 0.0046 - accuracy: 0.9727\n",
      "Epoch 42/100\n",
      "3750/3750 [==============================] - 3s 900us/step - loss: 0.0045 - accuracy: 0.9741\n",
      "Epoch 43/100\n",
      "3750/3750 [==============================] - 3s 908us/step - loss: 0.0046 - accuracy: 0.9732\n",
      "Epoch 44/100\n",
      "3750/3750 [==============================] - 3s 914us/step - loss: 0.0044 - accuracy: 0.9744\n",
      "Epoch 45/100\n",
      "3750/3750 [==============================] - 3s 911us/step - loss: 0.0043 - accuracy: 0.9750\n",
      "Epoch 46/100\n",
      "3750/3750 [==============================] - 3s 917us/step - loss: 0.0044 - accuracy: 0.9748\n",
      "Epoch 47/100\n",
      "3750/3750 [==============================] - 3s 920us/step - loss: 0.0044 - accuracy: 0.9743\n",
      "Epoch 48/100\n",
      "3750/3750 [==============================] - 3s 915us/step - loss: 0.0045 - accuracy: 0.9739\n",
      "Epoch 49/100\n",
      "3750/3750 [==============================] - 4s 944us/step - loss: 0.0043 - accuracy: 0.9754\n",
      "Epoch 50/100\n",
      "3750/3750 [==============================] - 4s 934us/step - loss: 0.0043 - accuracy: 0.9750\n",
      "Epoch 51/100\n",
      "3750/3750 [==============================] - 3s 910us/step - loss: 0.0042 - accuracy: 0.9756\n",
      "Epoch 52/100\n",
      "3750/3750 [==============================] - 3s 923us/step - loss: 0.0042 - accuracy: 0.9751\n",
      "Epoch 53/100\n",
      "3750/3750 [==============================] - 3s 903us/step - loss: 0.0043 - accuracy: 0.9749\n",
      "Epoch 54/100\n",
      "3750/3750 [==============================] - 4s 963us/step - loss: 0.0042 - accuracy: 0.9757\n",
      "Epoch 55/100\n",
      "3750/3750 [==============================] - 4s 959us/step - loss: 0.0042 - accuracy: 0.9750\n",
      "Epoch 56/100\n",
      "3750/3750 [==============================] - 4s 941us/step - loss: 0.0042 - accuracy: 0.9753\n",
      "Epoch 57/100\n",
      "3750/3750 [==============================] - 4s 948us/step - loss: 0.0039 - accuracy: 0.9773\n",
      "Epoch 58/100\n",
      "3750/3750 [==============================] - 4s 961us/step - loss: 0.0039 - accuracy: 0.9774\n",
      "Epoch 59/100\n",
      "3750/3750 [==============================] - 4s 941us/step - loss: 0.0039 - accuracy: 0.9774\n",
      "Epoch 60/100\n",
      "3750/3750 [==============================] - 4s 937us/step - loss: 0.0039 - accuracy: 0.9780\n",
      "Epoch 61/100\n",
      "3750/3750 [==============================] - 4s 937us/step - loss: 0.0039 - accuracy: 0.9777\n",
      "Epoch 62/100\n",
      "3750/3750 [==============================] - 3s 933us/step - loss: 0.0038 - accuracy: 0.9776\n",
      "Epoch 63/100\n",
      "3750/3750 [==============================] - 3s 933us/step - loss: 0.0038 - accuracy: 0.9787\n",
      "Epoch 64/100\n",
      "3750/3750 [==============================] - 3s 916us/step - loss: 0.0038 - accuracy: 0.9779\n",
      "Epoch 65/100\n",
      "3750/3750 [==============================] - 3s 930us/step - loss: 0.0038 - accuracy: 0.9784\n",
      "Epoch 66/100\n",
      "3750/3750 [==============================] - 3s 912us/step - loss: 0.0037 - accuracy: 0.9790\n",
      "Epoch 67/100\n",
      "3750/3750 [==============================] - 3s 905us/step - loss: 0.0037 - accuracy: 0.9793\n",
      "Epoch 68/100\n",
      "3750/3750 [==============================] - 3s 905us/step - loss: 0.0038 - accuracy: 0.9795\n",
      "Epoch 69/100\n",
      "3750/3750 [==============================] - 3s 927us/step - loss: 0.0037 - accuracy: 0.9791\n",
      "Epoch 70/100\n",
      "3750/3750 [==============================] - 3s 913us/step - loss: 0.0037 - accuracy: 0.9794\n",
      "Epoch 71/100\n",
      "3750/3750 [==============================] - 3s 926us/step - loss: 0.0037 - accuracy: 0.9797\n",
      "Epoch 72/100\n",
      "3750/3750 [==============================] - 3s 931us/step - loss: 0.0036 - accuracy: 0.9795\n",
      "Epoch 73/100\n",
      "3750/3750 [==============================] - 4s 994us/step - loss: 0.0037 - accuracy: 0.9794\n",
      "Epoch 74/100\n",
      "3750/3750 [==============================] - 4s 977us/step - loss: 0.0035 - accuracy: 0.9802\n",
      "Epoch 75/100\n",
      "3750/3750 [==============================] - 4s 939us/step - loss: 0.0034 - accuracy: 0.9813\n",
      "Epoch 76/100\n",
      "3750/3750 [==============================] - 3s 928us/step - loss: 0.0034 - accuracy: 0.9809\n",
      "Epoch 77/100\n",
      "3750/3750 [==============================] - 4s 985us/step - loss: 0.0035 - accuracy: 0.9807\n",
      "Epoch 78/100\n",
      "3750/3750 [==============================] - 4s 974us/step - loss: 0.0035 - accuracy: 0.9802\n",
      "Epoch 79/100\n",
      "3750/3750 [==============================] - 3s 927us/step - loss: 0.0034 - accuracy: 0.9807\n",
      "Epoch 80/100\n",
      "3750/3750 [==============================] - 3s 901us/step - loss: 0.0036 - accuracy: 0.9796\n",
      "Epoch 81/100\n",
      "3750/3750 [==============================] - 3s 900us/step - loss: 0.0034 - accuracy: 0.9812\n",
      "Epoch 82/100\n",
      "3750/3750 [==============================] - 3s 922us/step - loss: 0.0033 - accuracy: 0.9821\n",
      "Epoch 83/100\n",
      "3750/3750 [==============================] - 4s 936us/step - loss: 0.0035 - accuracy: 0.9798\n",
      "Epoch 84/100\n",
      "3750/3750 [==============================] - 3s 930us/step - loss: 0.0034 - accuracy: 0.9817\n",
      "Epoch 85/100\n",
      "3750/3750 [==============================] - 3s 917us/step - loss: 0.0033 - accuracy: 0.9814\n",
      "Epoch 86/100\n",
      "3750/3750 [==============================] - 3s 906us/step - loss: 0.0035 - accuracy: 0.9796\n",
      "Epoch 87/100\n",
      "3750/3750 [==============================] - 3s 918us/step - loss: 0.0033 - accuracy: 0.9810\n",
      "Epoch 88/100\n",
      "3750/3750 [==============================] - 3s 922us/step - loss: 0.0034 - accuracy: 0.9816\n",
      "Epoch 89/100\n",
      "3750/3750 [==============================] - 3s 922us/step - loss: 0.0031 - accuracy: 0.9831\n",
      "Epoch 90/100\n",
      "3750/3750 [==============================] - 4s 949us/step - loss: 0.0033 - accuracy: 0.9817\n",
      "Epoch 91/100\n",
      "3750/3750 [==============================] - 4s 946us/step - loss: 0.0034 - accuracy: 0.9815\n",
      "Epoch 92/100\n",
      "3750/3750 [==============================] - 3s 925us/step - loss: 0.0033 - accuracy: 0.9821\n",
      "Epoch 93/100\n",
      "3750/3750 [==============================] - 3s 914us/step - loss: 0.0032 - accuracy: 0.9824\n",
      "Epoch 94/100\n",
      "3750/3750 [==============================] - 3s 917us/step - loss: 0.0033 - accuracy: 0.9816\n",
      "Epoch 95/100\n",
      "3750/3750 [==============================] - 3s 908us/step - loss: 0.0032 - accuracy: 0.9824\n",
      "Epoch 96/100\n",
      "3750/3750 [==============================] - 3s 925us/step - loss: 0.0033 - accuracy: 0.9821\n",
      "Epoch 97/100\n",
      "3750/3750 [==============================] - 3s 913us/step - loss: 0.0033 - accuracy: 0.9816\n",
      "Epoch 98/100\n",
      "3750/3750 [==============================] - 3s 918us/step - loss: 0.0031 - accuracy: 0.9828\n",
      "Epoch 99/100\n",
      "3750/3750 [==============================] - 3s 927us/step - loss: 0.0031 - accuracy: 0.9834\n",
      "Epoch 100/100\n",
      "3750/3750 [==============================] - 3s 921us/step - loss: 0.0030 - accuracy: 0.9838\n"
     ]
    }
   ],
   "source": [
    "#historial\n",
    "history = model.fit(x_train,y_train,epochs=100,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 784us/step - loss: 0.0069 - accuracy: 0.9549\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.006922694388777018, 0.9549000263214111]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,ytest, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualización de la clasificación\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['loss'], label=['loss'])\n",
    "plt.title('Entrenamiento MNIST')\n",
    "plt.xlabel('Epocas')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_prueba = ((x_test[30].reshape(28,28) +0.5)*255).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = np.array(x_prueba, dtype='float')\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.41764706, -0.05686274,  0.25686276,  0.49607843,  0.49215686,\n",
       "        0.49607843,  0.49215686,  0.49607843,  0.17450982, -0.17843136,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       ,  0.21764708,  0.49215686,\n",
       "        0.4882353 ,  0.49215686,  0.4882353 ,  0.49215686,  0.4882353 ,\n",
       "        0.49215686,  0.4882353 ,  0.45294118, -0.34313726, -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       ,  0.29607844,  0.5       ,  0.4137255 ,  0.21764708,\n",
       "       -0.09999999,  0.29607844,  0.29607844,  0.41764706,  0.49215686,\n",
       "        0.49607843,  0.09215689, -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.18235293,\n",
       "        0.09215689, -0.30392158, -0.5       , -0.5       , -0.5       ,\n",
       "       -0.3392157 ,  0.25686276,  0.4882353 ,  0.49215686, -0.06470588,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.45686275,  0.33529413,  0.49607843,\n",
       "        0.49215686,  0.29607844, -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.01764706,\n",
       "        0.33529413,  0.4882353 ,  0.49215686,  0.4882353 , -0.18235293,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.3       ,  0.49215686,  0.49607843,  0.49215686,\n",
       "        0.49607843,  0.09215689, -0.41764706, -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.46078432,\n",
       "        0.33137256,  0.49215686,  0.4882353 ,  0.49215686,  0.40980393,\n",
       "        0.3745098 , -0.02156863, -0.17843136, -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.01764706,\n",
       "        0.3745098 ,  0.49607843,  0.49215686,  0.49607843,  0.49215686,\n",
       "        0.49607843, -0.22156861, -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.42156863, -0.30392158,\n",
       "        0.01372552,  0.33529413,  0.4882353 ,  0.49215686,  0.2529412 ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.41764706,\n",
       "        0.13529414,  0.49607843,  0.49215686, -0.09999999, -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.41764706,  0.29607844,  0.49215686,\n",
       "        0.4882353 , -0.26078433, -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        0.01764709,  0.49215686,  0.49607843, -0.14313725, -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.41764706,  0.05686277,  0.49215686,  0.4882353 ,\n",
       "        0.4137255 , -0.38235295, -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.3392157 ,  0.3392157 ,\n",
       "        0.49215686,  0.49607843,  0.33529413, -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        0.13921571,  0.45294118,  0.49215686,  0.4882353 ,  0.17450982,\n",
       "       -0.46078432, -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.45686275,\n",
       "        0.17843139,  0.17843139,  0.49215686,  0.5       ,  0.49215686,\n",
       "        0.37843138, -0.18235293, -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       ,  0.01764709,  0.4882353 ,  0.49215686,\n",
       "        0.4882353 ,  0.49215686,  0.17058825, -0.42156863, -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "        0.10000002,  0.49215686,  0.45686275,  0.29607844, -0.17843136,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.13921568,  0.2529412 ,\n",
       "       -0.02156863, -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       , -0.5       ,\n",
       "       -0.5       , -0.5       , -0.5       , -0.5       ], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[30].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest=x_test[30].reshape(784,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.41764706],\n",
       "       [-0.05686274],\n",
       "       [ 0.25686276],\n",
       "       [ 0.49607843],\n",
       "       [ 0.49215686],\n",
       "       [ 0.49607843],\n",
       "       [ 0.49215686],\n",
       "       [ 0.49607843],\n",
       "       [ 0.17450982],\n",
       "       [-0.17843136],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [ 0.21764708],\n",
       "       [ 0.49215686],\n",
       "       [ 0.4882353 ],\n",
       "       [ 0.49215686],\n",
       "       [ 0.4882353 ],\n",
       "       [ 0.49215686],\n",
       "       [ 0.4882353 ],\n",
       "       [ 0.49215686],\n",
       "       [ 0.4882353 ],\n",
       "       [ 0.45294118],\n",
       "       [-0.34313726],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [ 0.29607844],\n",
       "       [ 0.5       ],\n",
       "       [ 0.4137255 ],\n",
       "       [ 0.21764708],\n",
       "       [-0.09999999],\n",
       "       [ 0.29607844],\n",
       "       [ 0.29607844],\n",
       "       [ 0.41764706],\n",
       "       [ 0.49215686],\n",
       "       [ 0.49607843],\n",
       "       [ 0.09215689],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.18235293],\n",
       "       [ 0.09215689],\n",
       "       [-0.30392158],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.3392157 ],\n",
       "       [ 0.25686276],\n",
       "       [ 0.4882353 ],\n",
       "       [ 0.49215686],\n",
       "       [-0.06470588],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.45686275],\n",
       "       [ 0.33529413],\n",
       "       [ 0.49607843],\n",
       "       [ 0.49215686],\n",
       "       [ 0.29607844],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.01764706],\n",
       "       [ 0.33529413],\n",
       "       [ 0.4882353 ],\n",
       "       [ 0.49215686],\n",
       "       [ 0.4882353 ],\n",
       "       [-0.18235293],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.3       ],\n",
       "       [ 0.49215686],\n",
       "       [ 0.49607843],\n",
       "       [ 0.49215686],\n",
       "       [ 0.49607843],\n",
       "       [ 0.09215689],\n",
       "       [-0.41764706],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.46078432],\n",
       "       [ 0.33137256],\n",
       "       [ 0.49215686],\n",
       "       [ 0.4882353 ],\n",
       "       [ 0.49215686],\n",
       "       [ 0.40980393],\n",
       "       [ 0.3745098 ],\n",
       "       [-0.02156863],\n",
       "       [-0.17843136],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.01764706],\n",
       "       [ 0.3745098 ],\n",
       "       [ 0.49607843],\n",
       "       [ 0.49215686],\n",
       "       [ 0.49607843],\n",
       "       [ 0.49215686],\n",
       "       [ 0.49607843],\n",
       "       [-0.22156861],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.42156863],\n",
       "       [-0.30392158],\n",
       "       [ 0.01372552],\n",
       "       [ 0.33529413],\n",
       "       [ 0.4882353 ],\n",
       "       [ 0.49215686],\n",
       "       [ 0.2529412 ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.41764706],\n",
       "       [ 0.13529414],\n",
       "       [ 0.49607843],\n",
       "       [ 0.49215686],\n",
       "       [-0.09999999],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.41764706],\n",
       "       [ 0.29607844],\n",
       "       [ 0.49215686],\n",
       "       [ 0.4882353 ],\n",
       "       [-0.26078433],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [ 0.01764709],\n",
       "       [ 0.49215686],\n",
       "       [ 0.49607843],\n",
       "       [-0.14313725],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.41764706],\n",
       "       [ 0.05686277],\n",
       "       [ 0.49215686],\n",
       "       [ 0.4882353 ],\n",
       "       [ 0.4137255 ],\n",
       "       [-0.38235295],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.3392157 ],\n",
       "       [ 0.3392157 ],\n",
       "       [ 0.49215686],\n",
       "       [ 0.49607843],\n",
       "       [ 0.33529413],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [ 0.13921571],\n",
       "       [ 0.45294118],\n",
       "       [ 0.49215686],\n",
       "       [ 0.4882353 ],\n",
       "       [ 0.17450982],\n",
       "       [-0.46078432],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.45686275],\n",
       "       [ 0.17843139],\n",
       "       [ 0.17843139],\n",
       "       [ 0.49215686],\n",
       "       [ 0.5       ],\n",
       "       [ 0.49215686],\n",
       "       [ 0.37843138],\n",
       "       [-0.18235293],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [ 0.01764709],\n",
       "       [ 0.4882353 ],\n",
       "       [ 0.49215686],\n",
       "       [ 0.4882353 ],\n",
       "       [ 0.49215686],\n",
       "       [ 0.17058825],\n",
       "       [-0.42156863],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [ 0.10000002],\n",
       "       [ 0.49215686],\n",
       "       [ 0.45686275],\n",
       "       [ 0.29607844],\n",
       "       [-0.17843136],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.13921568],\n",
       "       [ 0.2529412 ],\n",
       "       [-0.02156863],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ],\n",
       "       [-0.5       ]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.3135534e-09, 4.2308270e-07, 7.5181089e-10, 9.9982554e-01,\n",
       "        8.9076491e-10, 6.5788940e-05, 5.1073767e-13, 1.0405352e-07,\n",
       "        7.4238055e-10, 1.0807928e-04]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(xtest.reshape(1,784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "toint=(model.predict(xtest.reshape(1,784))).round()\n",
    "int_test = toint.astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El número predecido es: 3\n"
     ]
    }
   ],
   "source": [
    "h/to/the/num_predict = int_test.argmax()\n",
    "print(\"El número predecido es:\",num_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conjuntos de entrenamiento, validación y test\n",
    "\n",
    "Si nos enfrentáramos a un problema de clasificación con responsabilildad deberíamos ser capaces de asegurar que el rendimiento que decimos que tiene nuestra red es el que realmente tiene (y no necesariamente una red, sino a cualquier modelo de clasificación que utilicemos. No solo de redes vive el experto en *machine learning*).\n",
    "\n",
    "Para ello, hasta ahora hemos hecho uso del conjunto de test. Pero, cuando entrenamos una red hacemos muchas pruebas, muchos cambios en su configuración (los hiperparámetros) buscando una de ellas que nos dé los mejores resultados. Llegará un momento en el que hemos hecho tantas modificaciones en la red que nuestro conjunto de test logrará un buen *accuracy*. Sin embargo, ¿cómo podemos estar seguros de que la red funcionaría bien para un nuevo conjunto de test? Es decir, quizá hayamos involuntariamente optimizado la red para que funcione bien sobre el conjunto de test.\n",
    "\n",
    "La forma de asegurar que hemos entrenado una red que **generaliza** correctamente es disponer de tres conjuntos: **entrenamiento**, **validación** y **test**. Con el de entrenamiento, entrenamos, y utilizaremos el conjunto de validación para comprobar el nivel de *accuracy* logrado en ese modelo. Al final de todas las pruebas que hayamos hecho, dispondremos de nuestro modelo final. En ese momento tomaremos nuestro conjunto de test (que previamente habíamos guardado bajo llave para evitar la tentación de utilizarlo antes) y lo pasaremos por la red. El *accuracy* que nos devuelva este conjunto de test será nuestro resultado final.\n",
    "\n",
    "Nosotros en las clases no nos vamos a preocupar mucho de esto, y utilizaremos el conjunto de test también como conjunto de validación. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
